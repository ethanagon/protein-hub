{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527f9fe7",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81675a",
   "metadata": {},
   "source": [
    "# GOR Method Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404c26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85325d7e",
   "metadata": {},
   "source": [
    "1. Build a GOR propensity matrix from the files in the propensity folder (for H,E and '-' categories)\n",
    "2. Create inference method to predict sites in protein sequence via GOR method\n",
    "3. Compare against secondary structure sequences from PDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708462a",
   "metadata": {},
   "source": [
    "## Create GOR Propensity Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aed26b",
   "metadata": {},
   "source": [
    "### Create Frequency Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a0c67",
   "metadata": {},
   "source": [
    "Output is three tables: one each for H, E, and '-'\n",
    "Each table has a row for each position relative to the focal residue and a column for each AA (The X column is dropped).\n",
    "I'm open to some swaps on that output, but I suspect it will make life a little easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac4947d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rows are in same order as the table in original GOR paper\n",
    "AA_LETTERS = ['G', 'A', 'V', 'L', 'I', 'S', 'T', 'D', 'E', 'N', 'Q', 'K', 'H', 'R', 'F', 'Y', 'W', 'C', 'M', 'P', 'X']\n",
    "STRUCTURE_KEYS = ['H', 'E', '-']\n",
    "WINDOW_RADIUS = 8\n",
    "\n",
    "# The X is a way to handle edges via padding, and is zeroed before calculating frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "717fb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_count_table():\n",
    "    return pd.DataFrame(0,index=np.arange(17),columns=AA_LETTERS)\n",
    "\n",
    "def init_class_counts():\n",
    "    return {'H': init_count_table(), 'E': init_count_table(), '-': init_count_table()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc7127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tables = init_class_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaae1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_seq_file(seqfile):\n",
    "    seq_class_counts = init_class_counts()\n",
    "    with open(seqfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        structure = lines[0].strip()\n",
    "        sequence = lines[1].strip()\n",
    "        padding = 'X' * 8\n",
    "        padded_seq = padding + sequence + padding\n",
    "    for i in range(0,len(structure)):\n",
    "        category = structure[i]\n",
    "        window_seqs = padded_seq[i:i+17]\n",
    "        for j in range(0,len(window_seqs)):\n",
    "            seq_class_counts[category].loc[j, window_seqs[j]] += 1\n",
    "    return seq_class_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a47ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r\"train/\"\n",
    "for filename in os.listdir(directory):\n",
    "    seq_class_counts = count_seq_file(os.path.join(directory,filename))\n",
    "    for key in seq_class_counts.keys():\n",
    "        count_tables[key] += seq_class_counts[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9171f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_count_tables = count_tables.copy()\n",
    "for key in count_tables.keys():\n",
    "    trimmed_count_tables[key][\"X\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61049e1",
   "metadata": {},
   "source": [
    "### Create Frequency Tables from Count Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48204681",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_freq_tables = {key: trimmed_count_tables[key].div(trimmed_count_tables[key].sum(axis=1),axis=0) for key in STRUCTURE_KEYS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6899936b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 0.3549997224198929, 'E': 0.22097899980317046, '-': 0.4240212777769366}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_totals = {key: trimmed_count_tables[key].loc[8].sum() for key in STRUCTURE_KEYS}   \n",
    "n_residues = sum(structure_totals.values()) \n",
    "structure_tot_freqs = {key: structure_totals[key]/n_residues for key in STRUCTURE_KEYS}\n",
    "structure_tot_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cea745d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_aa_counts = trimmed_count_tables[\"H\"] + trimmed_count_tables[\"E\"] + trimmed_count_tables[\"-\"]\n",
    "overall_aa_freqs = total_aa_counts.div(total_aa_counts.sum(axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16d565",
   "metadata": {},
   "source": [
    "### Create Information Tables From Frequency Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ccd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_tables = {key: np.log2(cond_freq_tables[key]/overall_aa_freqs) for key in STRUCTURE_KEYS}\n",
    "## Knuth forgive me for the kludge I am about to perform\n",
    "for key in info_tables.keys():\n",
    "    info_tables[key][\"X\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46754d7e",
   "metadata": {},
   "source": [
    "## Inference Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd1a6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_secondary_structure(sequence, info_tables):\n",
    "    WINDOW_RADIUS = 8\n",
    "    sequence = sequence.upper()\n",
    "    length = len(sequence)\n",
    "    pred_ss = []\n",
    "\n",
    "    for pos in range(length):\n",
    "        scores = {'H': 0.0, 'E': 0.0, '-': 0.0}\n",
    "        # Slide window centered on residue pos\n",
    "        for offset in range(-WINDOW_RADIUS, WINDOW_RADIUS+1):\n",
    "            j = pos + offset\n",
    "\n",
    "            # Skip positions that go outside sequence\n",
    "            if j < 0 or j >= length:\n",
    "                continue\n",
    "\n",
    "            aa = sequence[j]\n",
    "            if aa not in AA_LETTERS:\n",
    "                continue\n",
    "\n",
    "            # Add contribution from info table for each structure type\n",
    "            for key in STRUCTURE_KEYS:\n",
    "                scores[key] += info_tables[key].loc[offset + WINDOW_RADIUS, aa]\n",
    "\n",
    "        # Choose structure with highest total score\n",
    "        best_state = max(scores, key=scores.get)\n",
    "        pred_ss.append(best_state)\n",
    "\n",
    "    return ''.join(pred_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86396834",
   "metadata": {},
   "source": [
    "## Evaluate Against File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2c42fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(seq1, seq2):\n",
    "    return sum(s1 != s2 for s1, s2 in zip(seq1, seq2))\n",
    "\n",
    "def evaluate_file(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        struct_target = lines[0].strip()\n",
    "        seq_target = lines[1].strip()\n",
    "    struct_pred = predict_secondary_structure(seq_target, info_tables)\n",
    "    distance = hamming_distance(struct_target, struct_pred)\n",
    "    acc = distance / len(struct_target)\n",
    "    return [acc, struct_pred, struct_target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06d6d348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: EEEEEEEEE----HHEEEEEE------EEEEEE-----EEEEEE-------EEEEEE----------E-EEEEE-----E----------EE--E-----HHHHHHHHHHHHHHHHHHHEEE------EEEEEEE---------EEEE--EEEEEE------EEEE----HHEEEE------EEEEEE----EEEE---HH-EE--HHHH-EEEEEE----H----HHHEEEE------HHHHHHHHHH------H--EEEEEEE----HHHHHHEE-------------EEE----E\n",
      "trgt: -EEEEEEEE---HHHHHHHH---------HHHHHHHHHHHHHHH-------EEEEEE----------EEE-EEEE---EE-E-E----E-----EE--HHHHHHHHHHHHH-----EEE----E-HHHHHHHHHHH--------EEEEEEE---------HHHHHHHHHHHHHHHH------EEEEEEE-------------E--HHHHHHHHHHHHH-HHHH----HHHHHHHH---------HHHHHH-----EEEEEEEEEEEE--EEEEEEEEEE-----------EEEE----\n",
      "accuracy: 43.29%\n"
     ]
    }
   ],
   "source": [
    "test_file = \"train/23.dssp\" #Fairly long sequenve with stretches of all three structure classes\n",
    "test_acc, struct_pred, struct_target  = evaluate_file(test_file)\n",
    "print(f\"pred: {struct_pred}\")\n",
    "print(f\"trgt: {struct_target}\")\n",
    "print(f\"accuracy: {round(test_acc * 100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1e067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNHW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
